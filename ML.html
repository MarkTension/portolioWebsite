<!DOCTYPE html>
<html lang="en">
<head>

  <!-- load script
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
   <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
   <script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.12.4.min.js"></script>
    <script type="text/javascript" src="scripts/script.js"></script>


  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>MarkTension</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

  <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400&display=swap" rel="stylesheet">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="images/icons/favicon.png">

</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <!-- title
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">

    <!-- welcome ––––––––––––––––––––––––– -->
    <div class="row" align="right" style="margin-top:5%;margin-bottom:0%;">
        <a id="link2" href= "index.html"><h3>MarkTension</h3></a>

    </div>
    <div class="row">
      <div class="twelve columns fade" style="margin-top: 5%">
        <center>
          <a  href= "ML.html"><img style="margin-bottom:0%"  src="images/intro/actmax0.png" alt="icon" width="20%" opacity="1"></a>
          <a  href= "Music.html"><img style="margin-bottom:2%" class="dimmed" src="images/intro/actmax5.png" alt="icon" width="20%" opacity="0.5"></a>
          <a  href= "other.html"><img style="margin-bottom:6%"  class="dimmed" src="images/intro/actmax2.png" alt="icon" width="20%";></a>
          <center>

      </div>
    </div>


    <!-- menu row  –––––––––––––––––––––––––  -->
     <div class="row" >

      <!-- photo  ––––––––––––––––––––––––– -->
      <div class="four columns fade" > <center> <a id="link" href= "ML.html"> <h4 style="margin-top:15%" >MachineLearning </h4> </a> </center>
      </div>

    <!--  music ––––––––––––––––––––––––– -->


    <!-- word –––––––––––––––––––––-–––– -->
    <div class="four columns fade" > <center> <a id="link" href= "Music.html"> <h4 style="margin-top:10%">Music</h4> </a></center>
    </div>
    
    <div class="four columns fade" > <center> <a id="link" href="other.html"> <h4 style="margin-top:0%">Other</h4> </a></center>
    </div>
    </div>
    <div class=" twelve columns" align="left" style="margin-left: 20%,margin-right: 20%">
        <h5 > 2D & 3D sculpting with Unity </h5>
        <h6 style="margin-top:0%;align:justify;">
          As an ML-researcher/artist at Onformative, Berlin, I'm working on a 3D digital sculpting project in Unity3D.
          We're using reinforcement learning, enabled in Unity via its ml-agents library, to train an agent to creatively remove parts of a block to get to a desired outcome.
          The final version will have the agent using different tool shapes which will result in different aesthetics.
        </h6>

      <div class="twelve columns" style="margin-bottom:0%">     
        <img style="margin-top:0%" height="315"  align="center" src="images/ML/handFastGif.gif" width="50%" alt="hello">

        <iframe width="50%" height="315" align="right" src="https://www.youtube.com/embed/vJuxmydJQP4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
      </div>
      <div class="twelve columns" style="margin-bottom:10%">     
        <iframe width="50%" height="315" src="https://www.youtube.com/embed/h7aKyZKOP04" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>      </div>

    </div>
    <div class=" twelve columns" >
      <div class="six columns">
        <h5 > Visualizing image recogntion models' representations </h5>
        <h6 style="margin-top:0%;align:justify;">
          The biggest critique of using <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a> as models in science is that we don't know how exactly they compute.
          They're being called black box models for that reason. e.g. understanding a black box like the brain with another black box is not useful.
          However, various attempts have been made to get a better understanding of it, by presenting images, and visualizing the representations in different layers.
          One other way to do this is synthesizing input images by using gradient-ascent to maximise classification score on a selected class, filter, or neuron.
          This is called <a href="https://pdfs.semanticscholar.org/65d9/94fb778a8d9e0f632659fb33a082949a50d3.pdf">Activation Maximization</a>.
          To play with that, I used CIFAR10 to train a CNN and applied activatin maximization on it.
          </br></br>
          My results are visualizations of maximizing the classification of specific classes on Cifar10.
          I did get some good ones that looked like the various categories I was trying to visualize.
          However, after playing a bit more with it I got some unexpected results, displayed on the right.
          </br></br>

          A lot of the work is playing with different regularization techniques on updates to the synthetic input image.
          Stronger natural image priors are necessary to produce better visualizations with this gradient ascent technique.
          Playing around means adjusting the amount of the regularizations available.
          L2 regularization helped a lot, but I found that higher degrees of gaussian regularization (used in <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Mahendran_Understanding_Deep_Image_2015_CVPR_paper.html">this paper</a> to correlate pixels more with another)
          gave a really cool aesthetic to the output. It's all about finding the balance.
          My results were a bit overdone on the regularization-end.</br></br>
          I was quite surprised how the results didn't contain any strong features of the category they represented, yet they're rather beautiful.
          Another way to describe this is making <a href="https://openai.com/blog/adversarial-example-research/">adversarials</a> pretty.
        </h6>
      </div>
      <div class="six colums">
        <img style="margin-top:7%" src="images/intro/actmax0.png" width="15%" alt="hello">
        <img style="margin-top:2%" src="images/intro/actmax3.png" width="15%" alt="hello">
        <img style="margin-top:2%" src="images/intro/actmax4.png" width="15%" alt="hello">
      </div>

      <div class=" twelve columns" >
        <div class="six columns">
          <h5 > Multi Spectral Vision and image recognition on iOS  </h5>
          <h6 style="margin-top:0%;align:justify;">
            At Plant Vision we developed a demo to show our capabilities with infrared detection on the iPhone, and embedding neural networks in an iOS app to using image recognition.
            </br></br>
            This was all put together with the FLIR SDK, tensorflow-hub for transfer learning to custom categories, and ML-Core for embedding. All was glued together in Swift and Objective-C. 
            
          </h6>
        </div>
        <div class="six colums">
          <iframe width="50%" height="315" src="https://www.youtube.com/embed/0wcPZZdZIg0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

        </div>
      </div>

      <div class=" twelve columns" >
        <div class="six columns">
          <h5 > Reinforcement Learning / Neural Architecture Search </h5>
          <h6 style="margin-top:0%;align:justify;">
            For two semesters I did neuroscience/Machine-Learning research at MIT’s <a href="http://dicarlolab.mit.edu/">DiCarlo lab</a>. They specialise in a computational model approach to study the brain’s visual system. I was Supervised by prof. J. DiCarlo, dr. P. Bashivan and dr. J. Kubilius, in two projects:
            </br></br>
            One project was about using Neural Architecture Search for finding more brain-like models (<a href="https://arxiv.org/abs/1808.01405">Teacher Guided Architecture Search</a>). The idea is using Neural Architecture search to construct convolutional neural network architectures closer to the brain’s 'architecture'.
            This can be done by comparing the representations of visual input at various depths in the brain and model using <a href="https://www.mrc-cbu.cam.ac.uk/people/nikolaus.kriegeskorte/rsa/">Representational dissimilarity matrices</a>.
            Putting the simmilarity in the objective function steers the search into sampling more neural-like models.
            Here I learned and research a ton about reinforcement learning, by testing and implementing state of the art reinforcement learning optimisation algorithms (<a href="https://openai.com/blog/openai-baselines-ppo/">PPO</a>, and <a href="https://link.springer.com/article/10.1007/BF00992696"> REINFORCE</a>) to make the search more efficient.
            </br></br>
            The other project was using Neural Architecture Search for finding and analysing recurrent, and efficient cells for object recognition.
            This project was designed to steer the search into more parameter-sparse models by rewarding parameter sparsity in the optimizer's objective function.
            The model space we searched in were Cells of recurrent models (RNNs) for image recognition. Common implementations of these cells are <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">LSTM and GRU cells</a>.
          </h6>
        </div>
        <div class="six colums">
          <img style="margin-top:7%" src="images/ML/sage.png" width="50%" alt="hello">
          <img style="margin-top:2%" src="images/ML/GrassResearc.png" width="50%" alt="hello">
        </div>
      </div>

  </div>


<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
